{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhB8ZG9HaurP",
        "outputId": "cafaafca-5f57-4fa3-a20e-ab1925b845a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-31 18:51:37.331516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_tuner in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras_tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras_tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras->keras_tuner) (2.1.0)\n",
            "Requirement already satisfied: numpy in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras->keras_tuner) (13.9.1)\n",
            "Requirement already satisfied: namex in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras->keras_tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras->keras_tuner) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from keras->keras_tuner) (0.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from requests->keras_tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from requests->keras_tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from requests->keras_tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/fmunting/opt/anaconda3/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "! pip install keras_tuner\n",
        "import keras_tuner as kt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbeBRcGOa5Ra"
      },
      "outputs": [],
      "source": [
        "#df1 = pd.read_csv(\"data/large_board_dataset.csv\")\n",
        "df2 = pd.read_csv(\"large_board_dataset2.csv\")\n",
        "df3 = pd.read_csv(\"large_board_dataset3.csv\")\n",
        "#df4 = pd.read_csv(\"data/large_board_dataset2-mikala.csv\")\n",
        "#df4 = pd.read_csv(\"data/player_one_moves.csv\")\n",
        "#df5 = pd.read_csv(\"data/player_two_moves.csv\")\n",
        "\n",
        "\n",
        "df = pd.concat([df2, df3], axis =0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZnUR8HZhKF8"
      },
      "outputs": [],
      "source": [
        "df.head()\n",
        "df[\"x\"] = df[\"x\"].apply(lambda x: np.array(ast.literal_eval(x)).reshape(2, 6, 7))\n",
        "\n",
        "def preprocess_board(board):\n",
        "    if board[\"whose_turn\"] != \"red\":\n",
        "        # Flip the layers to make each board look like it's from the perspective of \"red\", aka plus\n",
        "        board[\"x\"] = board[\"x\"][::-1, :, :]\n",
        "    return board\n",
        "\n",
        "df = df.apply(preprocess_board, axis=1)\n",
        "\n",
        "def flip_board(board, col):\n",
        "    new_board = np.flip(board, axis = 2)\n",
        "    # for now this needs to be done by index 2 because the input is still 2x6x7, but this can easily be updated\n",
        "    new_column = 6 - col\n",
        "    return new_board, new_column\n",
        "\n",
        "flipped_x = []\n",
        "flipped_y = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    board = row[\"x\"]\n",
        "    col = row[\"y\"]\n",
        "    new_board, new_column = flip_board(board, col)\n",
        "\n",
        "    flipped_x.append(new_board)\n",
        "    flipped_y.append(new_column)\n",
        "\n",
        "new_df = pd.DataFrame({\"x\": flipped_x, \"y\": flipped_y})\n",
        "\n",
        "df = pd.concat([df, new_df], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJLuxlj1hRSN"
      },
      "outputs": [],
      "source": [
        "x = df[\"x\"]\n",
        "y = df[\"y\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 22)\n",
        "\n",
        "X_train = np.stack(X_train)\n",
        "X_test = np.stack(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_train = X_train.transpose(0, 2, 3, 1)  # Convert (num_samples, 2, 6, 7) to (num_samples, 6, 7, 2)\n",
        "X_test = X_test.transpose(0, 2, 3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "miILMAXNjOIc"
      },
      "outputs": [],
      "source": [
        "# TRYING WITH THE PICKLE FILE\n",
        "\n",
        "df = pd.read_pickle(\"data/654914moves_6-7-2shape.pkl\")\n",
        "x = df[\"x\"]\n",
        "y = df[\"y\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 22)\n",
        "\n",
        "X_train = np.stack(X_train)\n",
        "X_test = np.stack(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nz1pRmBAhndq"
      },
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "        model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=hp.Int('filters_1', min_value=32, max_value=128, step=32),\n",
        "                                kernel_size=(\n",
        "                                    hp.Int('kernel_size_1_height', min_value=2, max_value=4, step=1),\n",
        "                                    hp.Int('kernel_size_1_width', min_value=2, max_value=4, step=1)\n",
        "                                    ),\n",
        "                                activation=tf.nn.relu,\n",
        "                                input_shape=(6, 7, 2)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size =\n",
        "                                    (hp.Int('maxpool_size_1_height', min_value=1, max_value=4, step=1),\n",
        "                                    hp.Int('maxpool_size_1_width', min_value=1, max_value=4, step=1)\n",
        "                                    ),strides=(1, 1), padding = \"same\"),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=hp.Int('filters_2', min_value=32, max_value=128, step=32),\n",
        "                                kernel_size=(\n",
        "                                    hp.Int('kernel_size_2_height', min_value=2, max_value=4, step=1),\n",
        "                                    hp.Int('kernel_size_2_width', min_value=2, max_value=4, step=1)\n",
        "                                    ),\n",
        "                                activation=tf.nn.relu),\n",
        "\n",
        "        tf.keras.layers.MaxPooling2D(pool_size =\n",
        "                                    (hp.Int('maxpool_size_2_height', min_value=1, max_value=4, step=1),\n",
        "                                    hp.Int('maxpool_size_2_width', min_value=1, max_value=4, step=1)\n",
        "                                    ), strides = (1, 1), padding = \"same\"),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(hp.Int('dense_units_1', min_value = 32, max_value = 128, step = 32),\n",
        "                                activation=tf.nn.relu,\n",
        "                                kernel_regularizer = tf.keras.regularizers.l2(\n",
        "                                        hp.Choice('l2_reg_dense1', values = [0.0001, 0.0001, 0.005, 0.01])\n",
        "                                )),\n",
        "        tf.keras.layers.Dropout(hp.Float('dropout_1', min_value = 0.1, max_value = 0.4, step = 0.1)),\n",
        "        tf.keras.layers.Dense(hp.Int('dense_units_2', min_value = 32, max_value = 128, step = 32),activation=tf.nn.relu,\n",
        "                                kernel_regularizer = tf.keras.regularizers.l2(\n",
        "                                        hp.Choice('l2_reg_dense2', values = [0.0001, 0.0001, 0.005, 0.01])\n",
        "                                )),\n",
        "        tf.keras.layers.Dropout(hp.Float('dropout_2', min_value = 0.1, max_value = 0.4, step = 0.1)),\n",
        "        tf.keras.layers.Dense(7,activation=tf.nn.softmax)\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "                learning_rate = hp.Choice('learning_rate', values = [0.1, 0.001, 0.0001])),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6Xr7G_AmZ1",
        "outputId": "97350b0e-dcdd-4ed2-d164-bbd008e7a902"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/fmunting/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# now we have a tunable model; set up kt.Hyperband\n",
        "# hyperband paper: https://arxiv.org/pdf/1603.06560\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                    objective = 'val_accuracy',\n",
        "                    max_epochs = 10,\n",
        "                    factor = 3,\n",
        "                    directory = 'cnn_tuning',\n",
        "                    project_name = 'cnn_tuning_kt'\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSJXKxs6AnWa",
        "outputId": "459425c7-d9ed-46e1-8f76-12c117886db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 27 Complete [00h 12m 21s]\n",
            "val_accuracy: 0.5088035464286804\n",
            "\n",
            "Best val_accuracy So Far: 0.5816752314567566\n",
            "Total elapsed time: 02h 16m 11s\n"
          ]
        }
      ],
      "source": [
        "# add early stopping to reduce training time\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)\n",
        "\n",
        "# now run the search\n",
        "\n",
        "tuner.search(X_train, y_train, epochs = 50, validation_split = 0.2, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6xY5aYzAo3y",
        "outputId": "f3547899-a76d-470e-ac99-a2410c0d8beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Filters (Conv1): 128\n",
            "Best Kernel Height (Conv1): 4\n",
            "Best Kernel Width (Conv1): 3\n",
            "Best Kernel Height (Conv2): 3\n",
            "Best Kernel Width (Conv2): 4\n",
            "Best Filters (Conv2): 96\n",
            "Best Dense Units (Layer 1): 32\n",
            "Best Dense Units (Layer 2): 32\n",
            "Best Dropout Rate (Layer 1): 0.2\n",
            "Best Dropout Rate (Layer 2): 0.30000000000000004\n",
            "Best L2 Regularization (Layer 1): 0.0001\n",
            "Best L2 Regularization (Layer 2): 0.0001\n",
            "Best Learning Rate: 0.001\n",
            "Best Maxpool Height (Conv1): 2\n",
            "Best Maxpool Width (Conv1): 1\n",
            "Best Maxpool Height (Conv2): 3\n",
            "Best Maxpool Width (Conv2): 1\n"
          ]
        }
      ],
      "source": [
        "# get the best hyperparameters out:\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best Filters (Conv1): {best_hps.get('filters_1')}\")\n",
        "print(f\"Best Kernel Height (Conv1): {best_hps.get('kernel_size_1_height')}\")\n",
        "print(f\"Best Kernel Width (Conv1): {best_hps.get('kernel_size_1_width')}\")\n",
        "print(f\"Best Kernel Height (Conv2): {best_hps.get('kernel_size_2_height')}\")\n",
        "print(f\"Best Kernel Width (Conv2): {best_hps.get('kernel_size_2_width')}\")\n",
        "print(f\"Best Filters (Conv2): {best_hps.get('filters_2')}\")\n",
        "print(f\"Best Dense Units (Layer 1): {best_hps.get('dense_units_1')}\")\n",
        "print(f\"Best Dense Units (Layer 2): {best_hps.get('dense_units_2')}\")\n",
        "print(f\"Best Dropout Rate (Layer 1): {best_hps.get('dropout_1')}\")\n",
        "print(f\"Best Dropout Rate (Layer 2): {best_hps.get('dropout_2')}\")\n",
        "print(f\"Best L2 Regularization (Layer 1): {best_hps.get('l2_reg_dense1')}\")\n",
        "print(f\"Best L2 Regularization (Layer 2): {best_hps.get('l2_reg_dense2')}\")\n",
        "print(f\"Best Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "print(f\"Best Maxpool Height (Conv1): {best_hps.get('maxpool_size_1_height')}\")\n",
        "print(f\"Best Maxpool Width (Conv1): {best_hps.get('maxpool_size_1_width')}\")\n",
        "print(f\"Best Maxpool Height (Conv2): {best_hps.get('maxpool_size_2_height')}\")\n",
        "print(f\"Best Maxpool Width (Conv2): {best_hps.get('maxpool_size_2_width')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz5eqem7Ap89",
        "outputId": "a3d75ee7-808f-4cc3-91f6-87527951ec53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - accuracy: 0.4158 - loss: 1.5257 - val_accuracy: 0.5239 - val_loss: 1.2183\n",
            "Epoch 2/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - accuracy: 0.5127 - loss: 1.2840 - val_accuracy: 0.5392 - val_loss: 1.1811\n",
            "Epoch 3/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.5327 - loss: 1.2353 - val_accuracy: 0.5476 - val_loss: 1.1509\n",
            "Epoch 4/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.5437 - loss: 1.2056 - val_accuracy: 0.5617 - val_loss: 1.1243\n",
            "Epoch 5/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.5536 - loss: 1.1814 - val_accuracy: 0.5660 - val_loss: 1.1124\n",
            "Epoch 6/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.5581 - loss: 1.1661 - val_accuracy: 0.5666 - val_loss: 1.1097\n",
            "Epoch 7/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.5635 - loss: 1.1501 - val_accuracy: 0.5718 - val_loss: 1.0949\n",
            "Epoch 8/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.5707 - loss: 1.1364 - val_accuracy: 0.5776 - val_loss: 1.0885\n",
            "Epoch 9/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.5739 - loss: 1.1288 - val_accuracy: 0.5804 - val_loss: 1.0781\n",
            "Epoch 10/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.5791 - loss: 1.1142 - val_accuracy: 0.5851 - val_loss: 1.0708\n",
            "Epoch 11/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.5832 - loss: 1.1057 - val_accuracy: 0.5855 - val_loss: 1.0701\n",
            "Epoch 12/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.5854 - loss: 1.0987 - val_accuracy: 0.5870 - val_loss: 1.0669\n",
            "Epoch 13/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - accuracy: 0.5883 - loss: 1.0926 - val_accuracy: 0.5817 - val_loss: 1.0723\n",
            "Epoch 14/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.5907 - loss: 1.0857 - val_accuracy: 0.5869 - val_loss: 1.0666\n",
            "Epoch 15/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.5935 - loss: 1.0795 - val_accuracy: 0.5908 - val_loss: 1.0645\n",
            "Epoch 16/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.5936 - loss: 1.0767 - val_accuracy: 0.5900 - val_loss: 1.0644\n",
            "Epoch 17/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 5ms/step - accuracy: 0.5976 - loss: 1.0682 - val_accuracy: 0.5881 - val_loss: 1.0628\n",
            "Epoch 18/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6ms/step - accuracy: 0.5978 - loss: 1.0660 - val_accuracy: 0.5926 - val_loss: 1.0619\n",
            "Epoch 19/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.6003 - loss: 1.0603 - val_accuracy: 0.5919 - val_loss: 1.0557\n",
            "Epoch 20/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 1.0571 - val_accuracy: 0.5913 - val_loss: 1.0651\n",
            "Epoch 21/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6013 - loss: 1.0551 - val_accuracy: 0.5896 - val_loss: 1.0584\n",
            "Epoch 22/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - accuracy: 0.6039 - loss: 1.0498 - val_accuracy: 0.5933 - val_loss: 1.0560\n",
            "Epoch 23/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6036 - loss: 1.0460 - val_accuracy: 0.5951 - val_loss: 1.0591\n",
            "Epoch 24/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6057 - loss: 1.0439 - val_accuracy: 0.5954 - val_loss: 1.0561\n",
            "Epoch 25/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6068 - loss: 1.0409 - val_accuracy: 0.5920 - val_loss: 1.0584\n",
            "Epoch 26/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6101 - loss: 1.0325 - val_accuracy: 0.5918 - val_loss: 1.0577\n",
            "Epoch 27/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6094 - loss: 1.0354 - val_accuracy: 0.5900 - val_loss: 1.0623\n",
            "Epoch 28/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5ms/step - accuracy: 0.6109 - loss: 1.0297 - val_accuracy: 0.5935 - val_loss: 1.0566\n",
            "Epoch 29/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6124 - loss: 1.0265 - val_accuracy: 0.5970 - val_loss: 1.0614\n",
            "Epoch 30/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6135 - loss: 1.0259 - val_accuracy: 0.5947 - val_loss: 1.0621\n",
            "Epoch 31/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6145 - loss: 1.0238 - val_accuracy: 0.5953 - val_loss: 1.0579\n",
            "Epoch 32/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6149 - loss: 1.0214 - val_accuracy: 0.5947 - val_loss: 1.0585\n",
            "Epoch 33/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6165 - loss: 1.0162 - val_accuracy: 0.5939 - val_loss: 1.0589\n",
            "Epoch 34/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6153 - loss: 1.0172 - val_accuracy: 0.5970 - val_loss: 1.0552\n",
            "Epoch 35/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6171 - loss: 1.0156 - val_accuracy: 0.5940 - val_loss: 1.0583\n",
            "Epoch 36/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6167 - loss: 1.0162 - val_accuracy: 0.5892 - val_loss: 1.0639\n",
            "Epoch 37/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6181 - loss: 1.0134 - val_accuracy: 0.5950 - val_loss: 1.0587\n",
            "Epoch 38/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6184 - loss: 1.0095 - val_accuracy: 0.5935 - val_loss: 1.0740\n",
            "Epoch 39/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6175 - loss: 1.0103 - val_accuracy: 0.5918 - val_loss: 1.0642\n",
            "Epoch 40/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6202 - loss: 1.0057 - val_accuracy: 0.5956 - val_loss: 1.0637\n",
            "Epoch 41/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6195 - loss: 1.0060 - val_accuracy: 0.5925 - val_loss: 1.0599\n",
            "Epoch 42/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - accuracy: 0.6194 - loss: 1.0062 - val_accuracy: 0.5943 - val_loss: 1.0636\n",
            "Epoch 43/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6216 - loss: 1.0014 - val_accuracy: 0.5970 - val_loss: 1.0718\n",
            "Epoch 44/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6232 - loss: 1.0008 - val_accuracy: 0.5956 - val_loss: 1.0678\n",
            "Epoch 45/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6223 - loss: 0.9976 - val_accuracy: 0.5924 - val_loss: 1.0763\n",
            "Epoch 46/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - accuracy: 0.6236 - loss: 0.9969 - val_accuracy: 0.5947 - val_loss: 1.0608\n",
            "Epoch 47/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6227 - loss: 0.9983 - val_accuracy: 0.5939 - val_loss: 1.0725\n",
            "Epoch 48/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6242 - loss: 0.9950 - val_accuracy: 0.5954 - val_loss: 1.0748\n",
            "Epoch 49/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6268 - loss: 0.9907 - val_accuracy: 0.5950 - val_loss: 1.0744\n",
            "Epoch 50/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6257 - loss: 0.9930 - val_accuracy: 0.5942 - val_loss: 1.0728\n",
            "Epoch 51/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6241 - loss: 0.9943 - val_accuracy: 0.5964 - val_loss: 1.0666\n",
            "Epoch 52/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6240 - loss: 0.9909 - val_accuracy: 0.5946 - val_loss: 1.0683\n",
            "Epoch 53/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6266 - loss: 0.9892 - val_accuracy: 0.5961 - val_loss: 1.0739\n",
            "Epoch 54/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - accuracy: 0.6280 - loss: 0.9888 - val_accuracy: 0.5947 - val_loss: 1.0675\n",
            "Epoch 55/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - accuracy: 0.6278 - loss: 0.9876 - val_accuracy: 0.5946 - val_loss: 1.0762\n",
            "Epoch 56/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 0.9859 - val_accuracy: 0.5958 - val_loss: 1.0741\n",
            "Epoch 57/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - accuracy: 0.6292 - loss: 0.9855 - val_accuracy: 0.5971 - val_loss: 1.0744\n",
            "Epoch 58/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 5ms/step - accuracy: 0.6279 - loss: 0.9858 - val_accuracy: 0.5975 - val_loss: 1.0875\n",
            "Epoch 59/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6289 - loss: 0.9838 - val_accuracy: 0.5953 - val_loss: 1.0814\n",
            "Epoch 60/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6299 - loss: 0.9827 - val_accuracy: 0.5961 - val_loss: 1.0656\n",
            "Epoch 61/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6279 - loss: 0.9825 - val_accuracy: 0.5978 - val_loss: 1.0799\n",
            "Epoch 62/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6297 - loss: 0.9801 - val_accuracy: 0.5983 - val_loss: 1.0834\n",
            "Epoch 63/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6309 - loss: 0.9767 - val_accuracy: 0.5982 - val_loss: 1.0664\n",
            "Epoch 64/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6316 - loss: 0.9775 - val_accuracy: 0.5952 - val_loss: 1.0703\n",
            "Epoch 65/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6327 - loss: 0.9747 - val_accuracy: 0.5993 - val_loss: 1.0782\n",
            "Epoch 66/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 5ms/step - accuracy: 0.6307 - loss: 0.9780 - val_accuracy: 0.5978 - val_loss: 1.0898\n",
            "Epoch 67/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - accuracy: 0.6314 - loss: 0.9748 - val_accuracy: 0.5945 - val_loss: 1.0798\n",
            "Epoch 68/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 0.9753 - val_accuracy: 0.5973 - val_loss: 1.0829\n",
            "Epoch 69/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - accuracy: 0.6328 - loss: 0.9730 - val_accuracy: 0.5941 - val_loss: 1.0768\n",
            "Epoch 70/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - accuracy: 0.6326 - loss: 0.9744 - val_accuracy: 0.5968 - val_loss: 1.0914\n",
            "Epoch 71/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - accuracy: 0.6322 - loss: 0.9731 - val_accuracy: 0.5936 - val_loss: 1.0744\n",
            "Epoch 72/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - accuracy: 0.6339 - loss: 0.9723 - val_accuracy: 0.5909 - val_loss: 1.0924\n",
            "Epoch 73/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - accuracy: 0.6340 - loss: 0.9693 - val_accuracy: 0.5946 - val_loss: 1.0934\n",
            "Epoch 74/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - accuracy: 0.6333 - loss: 0.9676 - val_accuracy: 0.5961 - val_loss: 1.0930\n",
            "Epoch 75/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6361 - loss: 0.9660 - val_accuracy: 0.5947 - val_loss: 1.0795\n",
            "Epoch 76/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6358 - loss: 0.9673 - val_accuracy: 0.5930 - val_loss: 1.0726\n",
            "Epoch 77/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - accuracy: 0.6335 - loss: 0.9694 - val_accuracy: 0.5964 - val_loss: 1.0767\n",
            "Epoch 78/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6ms/step - accuracy: 0.6342 - loss: 0.9683 - val_accuracy: 0.5963 - val_loss: 1.1000\n",
            "Epoch 79/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - accuracy: 0.6356 - loss: 0.9675 - val_accuracy: 0.5949 - val_loss: 1.0782\n",
            "Epoch 80/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6ms/step - accuracy: 0.6367 - loss: 0.9645 - val_accuracy: 0.5958 - val_loss: 1.0853\n",
            "Epoch 81/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 6ms/step - accuracy: 0.6341 - loss: 0.9672 - val_accuracy: 0.5959 - val_loss: 1.0857\n",
            "Epoch 82/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6ms/step - accuracy: 0.6351 - loss: 0.9666 - val_accuracy: 0.5968 - val_loss: 1.0827\n",
            "Epoch 83/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6ms/step - accuracy: 0.6349 - loss: 0.9665 - val_accuracy: 0.5963 - val_loss: 1.0866\n",
            "Epoch 84/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6ms/step - accuracy: 0.6361 - loss: 0.9641 - val_accuracy: 0.5967 - val_loss: 1.0886\n",
            "Epoch 85/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6ms/step - accuracy: 0.6369 - loss: 0.9640 - val_accuracy: 0.5886 - val_loss: 1.0976\n",
            "Epoch 86/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - accuracy: 0.6366 - loss: 0.9616 - val_accuracy: 0.5976 - val_loss: 1.0958\n",
            "Epoch 87/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 6ms/step - accuracy: 0.6362 - loss: 0.9611 - val_accuracy: 0.5930 - val_loss: 1.0968\n",
            "Epoch 88/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - accuracy: 0.6368 - loss: 0.9631 - val_accuracy: 0.5961 - val_loss: 1.0898\n",
            "Epoch 89/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6ms/step - accuracy: 0.6382 - loss: 0.9573 - val_accuracy: 0.5961 - val_loss: 1.0833\n",
            "Epoch 90/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - accuracy: 0.6385 - loss: 0.9591 - val_accuracy: 0.5914 - val_loss: 1.0984\n",
            "Epoch 91/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - accuracy: 0.6358 - loss: 0.9618 - val_accuracy: 0.5941 - val_loss: 1.0887\n",
            "Epoch 92/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 6ms/step - accuracy: 0.6371 - loss: 0.9594 - val_accuracy: 0.5951 - val_loss: 1.0868\n",
            "Epoch 93/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - accuracy: 0.6388 - loss: 0.9566 - val_accuracy: 0.5970 - val_loss: 1.1023\n",
            "Epoch 94/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - accuracy: 0.6391 - loss: 0.9567 - val_accuracy: 0.6001 - val_loss: 1.0938\n",
            "Epoch 95/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6386 - loss: 0.9579 - val_accuracy: 0.5975 - val_loss: 1.0947\n",
            "Epoch 96/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 5ms/step - accuracy: 0.6372 - loss: 0.9592 - val_accuracy: 0.5976 - val_loss: 1.0934\n",
            "Epoch 97/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 6ms/step - accuracy: 0.6376 - loss: 0.9568 - val_accuracy: 0.5943 - val_loss: 1.0935\n",
            "Epoch 98/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 5ms/step - accuracy: 0.6394 - loss: 0.9550 - val_accuracy: 0.5976 - val_loss: 1.0885\n",
            "Epoch 99/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.6404 - loss: 0.9550 - val_accuracy: 0.5922 - val_loss: 1.1117\n",
            "Epoch 100/100\n",
            "\u001b[1m13099/13099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 5ms/step - accuracy: 0.6392 - loss: 0.9565 - val_accuracy: 0.5922 - val_loss: 1.1004\n",
            "\u001b[1m4094/4094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5915 - loss: 1.0980\n",
            "Test accuracy: 0.5926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# train the best model on the full dataset\n",
        "\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = best_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# save the best model for future use\n",
        "best_model.save('best_connect4_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSj4gtGFt6II",
        "outputId": "e021f1bd-04d3-49fa-90dc-d4f2496fb01e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4094/4094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.5915 - loss: 1.0980\n",
            "Test accuracy: 0.5926\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.19 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "vscode": {
      "interpreter": {
        "hash": "f3c82d000bb8a1750346fb87c49af9771012dc5d265e5e793ee442432926adf7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
