{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhB8ZG9HaurP",
        "outputId": "cafaafca-5f57-4fa3-a20e-ab1925b845a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-04 09:19:00.871451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "#! pip install keras_tuner\n",
        "import keras_tuner as kt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbeBRcGOa5Ra"
      },
      "outputs": [],
      "source": [
        "#df1 = pd.read_csv(\"data/large_board_dataset.csv\")\n",
        "df2 = pd.read_csv(\"large_board_dataset2.csv\")\n",
        "df3 = pd.read_csv(\"large_board_dataset3.csv\")\n",
        "#df4 = pd.read_csv(\"data/large_board_dataset2-mikala.csv\")\n",
        "#df4 = pd.read_csv(\"data/player_one_moves.csv\")\n",
        "#df5 = pd.read_csv(\"data/player_two_moves.csv\")\n",
        "\n",
        "\n",
        "df = pd.concat([df2, df3], axis =0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZnUR8HZhKF8"
      },
      "outputs": [],
      "source": [
        "df.head()\n",
        "df[\"x\"] = df[\"x\"].apply(lambda x: np.array(ast.literal_eval(x)).reshape(2, 6, 7))\n",
        "\n",
        "def preprocess_board(board):\n",
        "    if board[\"whose_turn\"] != \"red\":\n",
        "        # Flip the layers to make each board look like it's from the perspective of \"red\", aka plus\n",
        "        board[\"x\"] = board[\"x\"][::-1, :, :]\n",
        "    return board\n",
        "\n",
        "df = df.apply(preprocess_board, axis=1)\n",
        "\n",
        "def flip_board(board, col):\n",
        "    new_board = np.flip(board, axis = 2)\n",
        "    # for now this needs to be done by index 2 because the input is still 2x6x7, but this can easily be updated\n",
        "    new_column = 6 - col\n",
        "    return new_board, new_column\n",
        "\n",
        "flipped_x = []\n",
        "flipped_y = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    board = row[\"x\"]\n",
        "    col = row[\"y\"]\n",
        "    new_board, new_column = flip_board(board, col)\n",
        "\n",
        "    flipped_x.append(new_board)\n",
        "    flipped_y.append(new_column)\n",
        "\n",
        "new_df = pd.DataFrame({\"x\": flipped_x, \"y\": flipped_y})\n",
        "\n",
        "df = pd.concat([df, new_df], ignore_index = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJLuxlj1hRSN"
      },
      "outputs": [],
      "source": [
        "x = df[\"x\"]\n",
        "y = df[\"y\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 22)\n",
        "\n",
        "X_train = np.stack(X_train)\n",
        "X_test = np.stack(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_train = X_train.transpose(0, 2, 3, 1)  # Convert (num_samples, 2, 6, 7) to (num_samples, 6, 7, 2)\n",
        "X_test = X_test.transpose(0, 2, 3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "miILMAXNjOIc"
      },
      "outputs": [],
      "source": [
        "# TRYING WITH THE PICKLE FILE\n",
        "\n",
        "df = pd.read_pickle(\"data/6-7-2shape_cleaned.pkl\")\n",
        "x = df[\"x\"]\n",
        "y = df[\"y\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 22)\n",
        "\n",
        "X_train = np.stack(X_train)\n",
        "X_test = np.stack(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nz1pRmBAhndq"
      },
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "        model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=hp.Int('filters_1', min_value=32, max_value=256, step=32),\n",
        "                                kernel_size=(\n",
        "                                    hp.Int('kernel_size_1_height', min_value=2, max_value=4, step=1),\n",
        "                                    hp.Int('kernel_size_1_width', min_value=2, max_value=4, step=1)\n",
        "                                    ),\n",
        "                                activation=tf.nn.relu,\n",
        "                                input_shape=(6, 7, 2),\n",
        "                                padding = \"same\"),\n",
        "        #tf.keras.layers.MaxPooling2D(pool_size =\n",
        "        #                            (hp.Int('maxpool_size_1_height', min_value=1, max_value=4, step=1),\n",
        "        #                            hp.Int('maxpool_size_1_width', min_value=1, max_value=4, step=1)\n",
        "        #                            ),strides=(1, 1), padding = \"same\"),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=hp.Int('filters_2', min_value=32, max_value=128, step=32),\n",
        "                                kernel_size=(\n",
        "                                    hp.Int('kernel_size_2_height', min_value=2, max_value=3, step=1),\n",
        "                                    hp.Int('kernel_size_2_width', min_value=2, max_value=3, step=1)\n",
        "                                    ),\n",
        "                                activation=tf.nn.relu,\n",
        "                                padding = \"same\"),\n",
        "\n",
        "        #tf.keras.layers.MaxPooling2D(pool_size =\n",
        "        #                            (hp.Int('maxpool_size_2_height', min_value=2, max_value=4, step=1),\n",
        "        #                            hp.Int('maxpool_size_2_width', min_value=2, max_value=4, step=1)\n",
        "         #                           ), strides = (1, 1), padding = \"same\"),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=hp.Int('filters_3', min_value=32, max_value=128, step=32),\n",
        "                                kernel_size=(\n",
        "                                    hp.Int('kernel_size_3_height', min_value=2, max_value=4, step=1),\n",
        "                                    hp.Int('kernel_size_3_width', min_value=2, max_value=4, step=1)\n",
        "                                    ),\n",
        "                                activation=tf.nn.relu,\n",
        "                                padding = \"same\"),\n",
        "                                \n",
        "        #tf.keras.layers.MaxPooling2D(pool_size =\n",
        "        #                            (hp.Int('maxpool_size_3_height', min_value=1, max_value=4, step=1),\n",
        "        #                            hp.Int('maxpool_size_3_width', min_value=1, max_value=4, step=1)\n",
        "        #                            ), strides = (1, 1), padding = \"same\"),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(hp.Int('dense_units_1', min_value = 32, max_value = 128, step = 32),\n",
        "                                activation=tf.nn.relu,\n",
        "                                kernel_regularizer = tf.keras.regularizers.l2(\n",
        "                                        hp.Choice('l2_reg_dense1', values = [0.0001, 0.001, 0.005, 0.01])\n",
        "                                )),\n",
        "        tf.keras.layers.Dropout(hp.Float('dropout_1', min_value = 0.1, max_value = 0.4, step = 0.1)),\n",
        "        tf.keras.layers.Dense(hp.Int('dense_units_2', min_value = 32, max_value = 128, step = 32),activation=tf.nn.relu,\n",
        "                                kernel_regularizer = tf.keras.regularizers.l2(\n",
        "                                        hp.Choice('l2_reg_dense2', values = [0.0001, 0.001, 0.005, 0.01])\n",
        "                                )),\n",
        "        tf.keras.layers.Dropout(hp.Float('dropout_2', min_value = 0.1, max_value = 0.4, step = 0.1)),\n",
        "        tf.keras.layers.Dense(7,activation=tf.nn.softmax)\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "                learning_rate = hp.Choice('learning_rate', values = [0.1, 0.001, 0.0001])),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec6Xr7G_AmZ1",
        "outputId": "97350b0e-dcdd-4ed2-d164-bbd008e7a902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from cnn_tuning/cnn_tuning_kt/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "# now we have a tunable model; set up kt.Hyperband\n",
        "# hyperband paper: https://arxiv.org/pdf/1603.06560\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                    objective = 'val_accuracy',\n",
        "                    max_epochs = 10,\n",
        "                    factor = 3,\n",
        "                    directory = 'cnn_tuning',\n",
        "                    project_name = 'cnn_tuning_kt'\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSJXKxs6AnWa",
        "outputId": "459425c7-d9ed-46e1-8f76-12c117886db9"
      },
      "outputs": [],
      "source": [
        "# add early stopping to reduce training time\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)\n",
        "\n",
        "# now run the search\n",
        "\n",
        "tuner.search(X_train, y_train, epochs = 30, validation_split = 0.2, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6xY5aYzAo3y",
        "outputId": "f3547899-a76d-470e-ac99-a2410c0d8beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Filters (Conv1): 160\n",
            "Best Kernel Height (Conv1): 4\n",
            "Best Kernel Width (Conv1): 2\n",
            "Best Kernel Height (Conv2): 3\n",
            "Best Kernel Width (Conv2): 3\n",
            "Best Kernel Height (Conv3): 3\n",
            "Best Kernel Width (Conv3): 4\n",
            "Best Filters (Conv2): 96\n",
            "Best Filters (Conv3): 128\n",
            "Best Dense Units (Layer 1): 128\n",
            "Best Dense Units (Layer 2): 96\n",
            "Best Dropout Rate (Layer 1): 0.4\n",
            "Best Dropout Rate (Layer 2): 0.1\n",
            "Best L2 Regularization (Layer 1): 0.0001\n",
            "Best L2 Regularization (Layer 2): 0.001\n",
            "Best Learning Rate: 0.001\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'print(f\"Best Maxpool Height (Conv1): {best_hps.get(\\'maxpool_size_1_height\\')}\")\\nprint(f\"Best Maxpool Width (Conv1): {best_hps.get(\\'maxpool_size_1_width\\')}\")\\nprint(f\"Best Maxpool Height (Conv2): {best_hps.get(\\'maxpool_size_2_height\\')}\")\\nprint(f\"Best Maxpool Width (Conv2): {best_hps.get(\\'maxpool_size_2_width\\')}\")\\nprint(f\"Best Maxpool Height (Conv3): {best_hps.get(\\'maxpool_size_3_height\\')}\")\\nprint(f\"Best Maxpool Width (Conv3): {best_hps.get(\\'maxpool_size_3_width\\')}\")'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the best hyperparameters out:\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best Filters (Conv1): {best_hps.get('filters_1')}\")\n",
        "print(f\"Best Kernel Height (Conv1): {best_hps.get('kernel_size_1_height')}\")\n",
        "print(f\"Best Kernel Width (Conv1): {best_hps.get('kernel_size_1_width')}\")\n",
        "print(f\"Best Kernel Height (Conv2): {best_hps.get('kernel_size_2_height')}\")\n",
        "print(f\"Best Kernel Width (Conv2): {best_hps.get('kernel_size_2_width')}\")\n",
        "print(f\"Best Kernel Height (Conv3): {best_hps.get('kernel_size_3_height')}\")\n",
        "print(f\"Best Kernel Width (Conv3): {best_hps.get('kernel_size_3_width')}\")\n",
        "print(f\"Best Filters (Conv2): {best_hps.get('filters_2')}\")\n",
        "print(f\"Best Filters (Conv3): {best_hps.get('filters_3')}\")\n",
        "print(f\"Best Dense Units (Layer 1): {best_hps.get('dense_units_1')}\")\n",
        "print(f\"Best Dense Units (Layer 2): {best_hps.get('dense_units_2')}\")\n",
        "print(f\"Best Dropout Rate (Layer 1): {best_hps.get('dropout_1')}\")\n",
        "print(f\"Best Dropout Rate (Layer 2): {best_hps.get('dropout_2')}\")\n",
        "print(f\"Best L2 Regularization (Layer 1): {best_hps.get('l2_reg_dense1')}\")\n",
        "print(f\"Best L2 Regularization (Layer 2): {best_hps.get('l2_reg_dense2')}\")\n",
        "print(f\"Best Learning Rate: {best_hps.get('learning_rate')}\")\n",
        "'''print(f\"Best Maxpool Height (Conv1): {best_hps.get('maxpool_size_1_height')}\")\n",
        "print(f\"Best Maxpool Width (Conv1): {best_hps.get('maxpool_size_1_width')}\")\n",
        "print(f\"Best Maxpool Height (Conv2): {best_hps.get('maxpool_size_2_height')}\")\n",
        "print(f\"Best Maxpool Width (Conv2): {best_hps.get('maxpool_size_2_width')}\")\n",
        "print(f\"Best Maxpool Height (Conv3): {best_hps.get('maxpool_size_3_height')}\")\n",
        "print(f\"Best Maxpool Width (Conv3): {best_hps.get('maxpool_size_3_width')}\")'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz5eqem7Ap89",
        "outputId": "a3d75ee7-808f-4cc3-91f6-87527951ec53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/fmunting/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 143ms/step - accuracy: 0.4071 - loss: 1.5440 - val_accuracy: 0.5467 - val_loss: 1.1832\n",
            "Epoch 2/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 136ms/step - accuracy: 0.5481 - loss: 1.1935 - val_accuracy: 0.5922 - val_loss: 1.0723\n",
            "Epoch 3/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 136ms/step - accuracy: 0.5979 - loss: 1.0760 - val_accuracy: 0.6142 - val_loss: 1.0146\n",
            "Epoch 4/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 136ms/step - accuracy: 0.6221 - loss: 1.0170 - val_accuracy: 0.6259 - val_loss: 0.9873\n",
            "Epoch 5/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 142ms/step - accuracy: 0.6359 - loss: 0.9771 - val_accuracy: 0.6315 - val_loss: 0.9757\n",
            "Epoch 6/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 142ms/step - accuracy: 0.6458 - loss: 0.9493 - val_accuracy: 0.6363 - val_loss: 0.9636\n",
            "Epoch 7/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 159ms/step - accuracy: 0.6581 - loss: 0.9208 - val_accuracy: 0.6369 - val_loss: 0.9618\n",
            "Epoch 8/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 157ms/step - accuracy: 0.6650 - loss: 0.9056 - val_accuracy: 0.6384 - val_loss: 0.9624\n",
            "Epoch 9/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 159ms/step - accuracy: 0.6711 - loss: 0.8894 - val_accuracy: 0.6389 - val_loss: 0.9674\n",
            "Epoch 10/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 160ms/step - accuracy: 0.6756 - loss: 0.8747 - val_accuracy: 0.6397 - val_loss: 0.9675\n",
            "Epoch 11/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 157ms/step - accuracy: 0.6817 - loss: 0.8616 - val_accuracy: 0.6402 - val_loss: 0.9719\n",
            "Epoch 12/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 156ms/step - accuracy: 0.6878 - loss: 0.8467 - val_accuracy: 0.6388 - val_loss: 0.9757\n",
            "Epoch 13/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 152ms/step - accuracy: 0.6917 - loss: 0.8387 - val_accuracy: 0.6421 - val_loss: 0.9780\n",
            "Epoch 14/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 151ms/step - accuracy: 0.6953 - loss: 0.8275 - val_accuracy: 0.6438 - val_loss: 0.9877\n",
            "Epoch 15/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 152ms/step - accuracy: 0.7014 - loss: 0.8166 - val_accuracy: 0.6421 - val_loss: 0.9871\n",
            "Epoch 16/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 161ms/step - accuracy: 0.7034 - loss: 0.8083 - val_accuracy: 0.6416 - val_loss: 1.0031\n",
            "Epoch 17/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 167ms/step - accuracy: 0.7076 - loss: 0.7998 - val_accuracy: 0.6401 - val_loss: 1.0113\n",
            "Epoch 18/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 181ms/step - accuracy: 0.7102 - loss: 0.7911 - val_accuracy: 0.6405 - val_loss: 1.0226\n",
            "Epoch 19/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 181ms/step - accuracy: 0.7132 - loss: 0.7851 - val_accuracy: 0.6377 - val_loss: 1.0140\n",
            "Epoch 20/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 178ms/step - accuracy: 0.7175 - loss: 0.7779 - val_accuracy: 0.6383 - val_loss: 1.0320\n",
            "Epoch 21/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 166ms/step - accuracy: 0.7195 - loss: 0.7688 - val_accuracy: 0.6389 - val_loss: 1.0319\n",
            "Epoch 22/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 149ms/step - accuracy: 0.7226 - loss: 0.7642 - val_accuracy: 0.6364 - val_loss: 1.0464\n",
            "Epoch 23/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 144ms/step - accuracy: 0.7238 - loss: 0.7591 - val_accuracy: 0.6390 - val_loss: 1.0732\n",
            "Epoch 24/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 166ms/step - accuracy: 0.7285 - loss: 0.7518 - val_accuracy: 0.6386 - val_loss: 1.0725\n",
            "Epoch 25/25\n",
            "\u001b[1m1533/1533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 160ms/step - accuracy: 0.7301 - loss: 0.7457 - val_accuracy: 0.6373 - val_loss: 1.0528\n",
            "\u001b[1m3742/3742\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.6340 - loss: 1.0535\n",
            "Test accuracy: 0.6350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# train the best model on the full dataset\n",
        "\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = best_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=25,\n",
        "    batch_size=250,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# save the best model for future use\n",
        "best_model.save('best_connect4_cnn_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSj4gtGFt6II",
        "outputId": "e021f1bd-04d3-49fa-90dc-d4f2496fb01e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3742/3742\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 9ms/step - accuracy: 0.6340 - loss: 1.0535\n",
            "Test accuracy: 0.6350\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.19 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "vscode": {
      "interpreter": {
        "hash": "f3c82d000bb8a1750346fb87c49af9771012dc5d265e5e793ee442432926adf7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
