{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_csv(\"data/large_board_dataset.csv\")\n",
    "df2 = pd.read_csv(\"data/large_board_dataset2.csv\")\n",
    "df3 = pd.read_csv(\"data/large_board_dataset3.csv\")\n",
    "#df4 = pd.read_csv(\"data/large_board_dataset2-mikala.csv\")\n",
    "#df4 = pd.read_csv(\"data/player_one_moves.csv\")\n",
    "#df5 = pd.read_csv(\"data/player_two_moves.csv\")\n",
    "\n",
    "\n",
    "df = pd.concat([df2, df3], axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df[\"x\"] = df[\"x\"].apply(lambda x: np.array(ast.literal_eval(x)).reshape(2, 6, 7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_board(board):\n",
    "    if board[\"whose_turn\"] != \"red\":\n",
    "        # Flip the layers to make each board look like it's from the perspective of \"red\", aka plus\n",
    "        board[\"x\"] = board[\"x\"][::-1, :, :]\n",
    "    return board\n",
    "\n",
    "df = df.apply(preprocess_board, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_board(board, col):\n",
    "    new_board = np.flip(board, axis = 2)\n",
    "    # for now this needs to be done by index 2 because the input is still 2x6x7, but this can easily be updated\n",
    "    new_column = 6 - col\n",
    "    return new_board, new_column\n",
    "\n",
    "flipped_x = []\n",
    "flipped_y = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    board = row[\"x\"]\n",
    "    col = row[\"y\"]\n",
    "    new_board, new_column = flip_board(board, col)\n",
    "\n",
    "    flipped_x.append(new_board)\n",
    "    flipped_y.append(new_column)\n",
    "\n",
    "new_df = pd.DataFrame({\"x\": flipped_x, \"y\": flipped_y})\n",
    "\n",
    "df = pd.concat([df, new_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/2_and_3_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "boards = df[\"x\"]\n",
    "columns = df[\"y\"]\n",
    "\n",
    "np.savez(\"data/final_data_jan_27.npz\", X = boards, y = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 1.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 1., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the below demonstrate that the flip_board() function works\n",
    "\n",
    "df[\"x\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 1., 0., 1., 0.]]]),\n",
       " 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_board(df[\"x\"][0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"x\"]\n",
    "y = df[\"y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 22)\n",
    "\n",
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)\n",
    "y_train = np.array(y_train)  \n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train = X_train.transpose(0, 2, 3, 1)  # Convert (num_samples, 2, 6, 7) to (num_samples, 6, 7, 2)\n",
    "X_test = X_test.transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fmunting/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=64,kernel_size=(4,4),activation=tf.nn.relu,input_shape=(6, 7, 2)),\n",
    "        # had to adjust data_format because it was treating the images as 2x6 with 7 channels\n",
    "        tf.keras.layers.MaxPooling2D(pool_size = (2,1),strides=(1, 1), padding = \"same\"),\n",
    "        tf.keras.layers.Conv2D(64, (2, 2), activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (1, 1), padding = \"same\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64,activation=tf.nn.relu,kernel_regularizer = tf.keras.regularizers.l2(0.005)),\n",
    "        tf.keras.layers.Dropout(0.1), \n",
    "        tf.keras.layers.Dense(64,activation=tf.nn.relu,kernel_regularizer = tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.Dropout(0.4), \n",
    "        tf.keras.layers.Dense(7,activation=tf.nn.softmax)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,815</span> (186.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,815\u001b[0m (186.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,815</span> (186.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,815\u001b[0m (186.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.2796 - loss: 1.9019 - val_accuracy: 0.4535 - val_loss: 1.4986\n",
      "Epoch 2/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.4560 - loss: 1.5094 - val_accuracy: 0.4933 - val_loss: 1.3908\n",
      "Epoch 3/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.4853 - loss: 1.4204 - val_accuracy: 0.5028 - val_loss: 1.3542\n",
      "Epoch 4/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.4994 - loss: 1.3819 - val_accuracy: 0.5148 - val_loss: 1.3143\n",
      "Epoch 5/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.5113 - loss: 1.3477 - val_accuracy: 0.5236 - val_loss: 1.2937\n",
      "Epoch 6/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5174 - loss: 1.3245 - val_accuracy: 0.5253 - val_loss: 1.2761\n",
      "Epoch 7/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5249 - loss: 1.3091 - val_accuracy: 0.5328 - val_loss: 1.2578\n",
      "Epoch 8/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5276 - loss: 1.2955 - val_accuracy: 0.5315 - val_loss: 1.2551\n",
      "Epoch 9/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.5307 - loss: 1.2799 - val_accuracy: 0.5368 - val_loss: 1.2420\n",
      "Epoch 10/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5345 - loss: 1.2710 - val_accuracy: 0.5377 - val_loss: 1.2299\n",
      "Epoch 11/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5393 - loss: 1.2575 - val_accuracy: 0.5435 - val_loss: 1.2257\n",
      "Epoch 12/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.5440 - loss: 1.2433 - val_accuracy: 0.5442 - val_loss: 1.2207\n",
      "Epoch 13/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5463 - loss: 1.2372 - val_accuracy: 0.5493 - val_loss: 1.2052\n",
      "Epoch 14/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5488 - loss: 1.2283 - val_accuracy: 0.5485 - val_loss: 1.2081\n",
      "Epoch 15/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.5526 - loss: 1.2179 - val_accuracy: 0.5523 - val_loss: 1.1990\n",
      "Epoch 16/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5532 - loss: 1.2154 - val_accuracy: 0.5536 - val_loss: 1.1937\n",
      "Epoch 17/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5573 - loss: 1.2092 - val_accuracy: 0.5542 - val_loss: 1.1909\n",
      "Epoch 18/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5598 - loss: 1.2002 - val_accuracy: 0.5581 - val_loss: 1.1835\n",
      "Epoch 19/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5621 - loss: 1.1920 - val_accuracy: 0.5612 - val_loss: 1.1785\n",
      "Epoch 20/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5641 - loss: 1.1900 - val_accuracy: 0.5573 - val_loss: 1.1815\n",
      "Epoch 21/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5661 - loss: 1.1875 - val_accuracy: 0.5588 - val_loss: 1.1770\n",
      "Epoch 22/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5658 - loss: 1.1807 - val_accuracy: 0.5595 - val_loss: 1.1740\n",
      "Epoch 23/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5665 - loss: 1.1815 - val_accuracy: 0.5656 - val_loss: 1.1614\n",
      "Epoch 24/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5698 - loss: 1.1677 - val_accuracy: 0.5614 - val_loss: 1.1722\n",
      "Epoch 25/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5710 - loss: 1.1673 - val_accuracy: 0.5613 - val_loss: 1.1654\n",
      "Epoch 26/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5717 - loss: 1.1657 - val_accuracy: 0.5642 - val_loss: 1.1678\n",
      "Epoch 27/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5732 - loss: 1.1609 - val_accuracy: 0.5618 - val_loss: 1.1692\n",
      "Epoch 28/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.5755 - loss: 1.1585 - val_accuracy: 0.5678 - val_loss: 1.1551\n",
      "Epoch 29/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5778 - loss: 1.1536 - val_accuracy: 0.5713 - val_loss: 1.1508\n",
      "Epoch 30/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5784 - loss: 1.1547 - val_accuracy: 0.5677 - val_loss: 1.1609\n",
      "Epoch 31/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5759 - loss: 1.1538 - val_accuracy: 0.5685 - val_loss: 1.1506\n",
      "Epoch 32/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5793 - loss: 1.1480 - val_accuracy: 0.5725 - val_loss: 1.1524\n",
      "Epoch 33/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5782 - loss: 1.1486 - val_accuracy: 0.5692 - val_loss: 1.1504\n",
      "Epoch 34/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5806 - loss: 1.1441 - val_accuracy: 0.5711 - val_loss: 1.1464\n",
      "Epoch 35/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5828 - loss: 1.1421 - val_accuracy: 0.5716 - val_loss: 1.1446\n",
      "Epoch 36/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5824 - loss: 1.1345 - val_accuracy: 0.5683 - val_loss: 1.1451\n",
      "Epoch 37/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5798 - loss: 1.1349 - val_accuracy: 0.5718 - val_loss: 1.1430\n",
      "Epoch 38/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5837 - loss: 1.1338 - val_accuracy: 0.5730 - val_loss: 1.1441\n",
      "Epoch 39/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5851 - loss: 1.1316 - val_accuracy: 0.5690 - val_loss: 1.1448\n",
      "Epoch 40/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5856 - loss: 1.1289 - val_accuracy: 0.5753 - val_loss: 1.1394\n",
      "Epoch 41/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5875 - loss: 1.1280 - val_accuracy: 0.5740 - val_loss: 1.1407\n",
      "Epoch 42/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5877 - loss: 1.1274 - val_accuracy: 0.5711 - val_loss: 1.1558\n",
      "Epoch 43/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5862 - loss: 1.1285 - val_accuracy: 0.5737 - val_loss: 1.1384\n",
      "Epoch 44/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5877 - loss: 1.1231 - val_accuracy: 0.5740 - val_loss: 1.1343\n",
      "Epoch 45/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5900 - loss: 1.1202 - val_accuracy: 0.5759 - val_loss: 1.1482\n",
      "Epoch 46/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5892 - loss: 1.1235 - val_accuracy: 0.5755 - val_loss: 1.1365\n",
      "Epoch 47/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5901 - loss: 1.1214 - val_accuracy: 0.5754 - val_loss: 1.1343\n",
      "Epoch 48/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5913 - loss: 1.1163 - val_accuracy: 0.5770 - val_loss: 1.1349\n",
      "Epoch 49/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5927 - loss: 1.1129 - val_accuracy: 0.5773 - val_loss: 1.1423\n",
      "Epoch 50/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5902 - loss: 1.1181 - val_accuracy: 0.5737 - val_loss: 1.1344\n",
      "Epoch 51/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5920 - loss: 1.1163 - val_accuracy: 0.5753 - val_loss: 1.1310\n",
      "Epoch 52/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5899 - loss: 1.1175 - val_accuracy: 0.5777 - val_loss: 1.1321\n",
      "Epoch 53/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5927 - loss: 1.1108 - val_accuracy: 0.5745 - val_loss: 1.1382\n",
      "Epoch 54/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5932 - loss: 1.1105 - val_accuracy: 0.5791 - val_loss: 1.1327\n",
      "Epoch 55/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5936 - loss: 1.1086 - val_accuracy: 0.5804 - val_loss: 1.1381\n",
      "Epoch 56/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5929 - loss: 1.1120 - val_accuracy: 0.5778 - val_loss: 1.1265\n",
      "Epoch 57/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5941 - loss: 1.1085 - val_accuracy: 0.5773 - val_loss: 1.1381\n",
      "Epoch 58/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 1.1068 - val_accuracy: 0.5771 - val_loss: 1.1260\n",
      "Epoch 59/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5941 - loss: 1.1071 - val_accuracy: 0.5754 - val_loss: 1.1370\n",
      "Epoch 60/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5956 - loss: 1.1034 - val_accuracy: 0.5808 - val_loss: 1.1236\n",
      "Epoch 61/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5959 - loss: 1.1016 - val_accuracy: 0.5778 - val_loss: 1.1303\n",
      "Epoch 62/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5943 - loss: 1.1045 - val_accuracy: 0.5826 - val_loss: 1.1268\n",
      "Epoch 63/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5975 - loss: 1.1001 - val_accuracy: 0.5780 - val_loss: 1.1349\n",
      "Epoch 64/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5977 - loss: 1.1009 - val_accuracy: 0.5789 - val_loss: 1.1299\n",
      "Epoch 65/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.5971 - loss: 1.0992 - val_accuracy: 0.5719 - val_loss: 1.1377\n",
      "Epoch 66/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.5944 - loss: 1.1030 - val_accuracy: 0.5783 - val_loss: 1.1378\n",
      "Epoch 67/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.5963 - loss: 1.1021 - val_accuracy: 0.5831 - val_loss: 1.1254\n",
      "Epoch 68/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 1.0937 - val_accuracy: 0.5797 - val_loss: 1.1325\n",
      "Epoch 69/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5962 - loss: 1.0964 - val_accuracy: 0.5813 - val_loss: 1.1361\n",
      "Epoch 70/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5969 - loss: 1.0961 - val_accuracy: 0.5779 - val_loss: 1.1377\n",
      "Epoch 71/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.6020 - loss: 1.0900 - val_accuracy: 0.5826 - val_loss: 1.1222\n",
      "Epoch 72/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.5999 - loss: 1.0943 - val_accuracy: 0.5848 - val_loss: 1.1226\n",
      "Epoch 73/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6007 - loss: 1.0910 - val_accuracy: 0.5820 - val_loss: 1.1215\n",
      "Epoch 74/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6009 - loss: 1.0915 - val_accuracy: 0.5817 - val_loss: 1.1324\n",
      "Epoch 75/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.6020 - loss: 1.0908 - val_accuracy: 0.5839 - val_loss: 1.1225\n",
      "Epoch 76/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6031 - loss: 1.0892 - val_accuracy: 0.5844 - val_loss: 1.1187\n",
      "Epoch 77/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6046 - loss: 1.0807 - val_accuracy: 0.5808 - val_loss: 1.1209\n",
      "Epoch 78/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5975 - loss: 1.0928 - val_accuracy: 0.5855 - val_loss: 1.1176\n",
      "Epoch 79/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.5996 - loss: 1.0884 - val_accuracy: 0.5842 - val_loss: 1.1302\n",
      "Epoch 80/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6025 - loss: 1.0831 - val_accuracy: 0.5812 - val_loss: 1.1256\n",
      "Epoch 81/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6017 - loss: 1.0846 - val_accuracy: 0.5797 - val_loss: 1.1285\n",
      "Epoch 82/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6025 - loss: 1.0856 - val_accuracy: 0.5835 - val_loss: 1.1211\n",
      "Epoch 83/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6039 - loss: 1.0854 - val_accuracy: 0.5800 - val_loss: 1.1291\n",
      "Epoch 84/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6041 - loss: 1.0841 - val_accuracy: 0.5839 - val_loss: 1.1189\n",
      "Epoch 85/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6041 - loss: 1.0818 - val_accuracy: 0.5831 - val_loss: 1.1264\n",
      "Epoch 86/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.6011 - loss: 1.0871 - val_accuracy: 0.5822 - val_loss: 1.1215\n",
      "Epoch 87/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6031 - loss: 1.0832 - val_accuracy: 0.5867 - val_loss: 1.1208\n",
      "Epoch 88/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6033 - loss: 1.0795 - val_accuracy: 0.5882 - val_loss: 1.1229\n",
      "Epoch 89/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6035 - loss: 1.0850 - val_accuracy: 0.5877 - val_loss: 1.1241\n",
      "Epoch 90/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6061 - loss: 1.0790 - val_accuracy: 0.5879 - val_loss: 1.1176\n",
      "Epoch 91/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6026 - loss: 1.0824 - val_accuracy: 0.5872 - val_loss: 1.1149\n",
      "Epoch 92/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6038 - loss: 1.0823 - val_accuracy: 0.5852 - val_loss: 1.1190\n",
      "Epoch 93/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6075 - loss: 1.0754 - val_accuracy: 0.5837 - val_loss: 1.1339\n",
      "Epoch 94/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6036 - loss: 1.0797 - val_accuracy: 0.5873 - val_loss: 1.1169\n",
      "Epoch 95/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6067 - loss: 1.0764 - val_accuracy: 0.5828 - val_loss: 1.1255\n",
      "Epoch 96/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6053 - loss: 1.0796 - val_accuracy: 0.5833 - val_loss: 1.1265\n",
      "Epoch 97/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6054 - loss: 1.0778 - val_accuracy: 0.5855 - val_loss: 1.1288\n",
      "Epoch 98/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6063 - loss: 1.0768 - val_accuracy: 0.5847 - val_loss: 1.1170\n",
      "Epoch 99/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6078 - loss: 1.0742 - val_accuracy: 0.5854 - val_loss: 1.1167\n",
      "Epoch 100/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6055 - loss: 1.0768 - val_accuracy: 0.5869 - val_loss: 1.1213\n",
      "Epoch 101/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 1.0815 - val_accuracy: 0.5887 - val_loss: 1.1155\n",
      "Epoch 102/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6073 - loss: 1.0714 - val_accuracy: 0.5888 - val_loss: 1.1137\n",
      "Epoch 103/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6098 - loss: 1.0715 - val_accuracy: 0.5860 - val_loss: 1.1182\n",
      "Epoch 104/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6097 - loss: 1.0677 - val_accuracy: 0.5826 - val_loss: 1.1260\n",
      "Epoch 105/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6057 - loss: 1.0746 - val_accuracy: 0.5888 - val_loss: 1.1098\n",
      "Epoch 106/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6081 - loss: 1.0730 - val_accuracy: 0.5820 - val_loss: 1.1240\n",
      "Epoch 107/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6059 - loss: 1.0790 - val_accuracy: 0.5858 - val_loss: 1.1251\n",
      "Epoch 108/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6074 - loss: 1.0761 - val_accuracy: 0.5886 - val_loss: 1.1203\n",
      "Epoch 109/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6086 - loss: 1.0710 - val_accuracy: 0.5895 - val_loss: 1.1108\n",
      "Epoch 110/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6087 - loss: 1.0740 - val_accuracy: 0.5893 - val_loss: 1.1168\n",
      "Epoch 111/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6098 - loss: 1.0728 - val_accuracy: 0.5899 - val_loss: 1.1191\n",
      "Epoch 112/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6084 - loss: 1.0728 - val_accuracy: 0.5861 - val_loss: 1.1175\n",
      "Epoch 113/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6104 - loss: 1.0685 - val_accuracy: 0.5916 - val_loss: 1.1241\n",
      "Epoch 114/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6113 - loss: 1.0698 - val_accuracy: 0.5890 - val_loss: 1.1139\n",
      "Epoch 115/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6103 - loss: 1.0644 - val_accuracy: 0.5854 - val_loss: 1.1126\n",
      "Epoch 116/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6095 - loss: 1.0655 - val_accuracy: 0.5907 - val_loss: 1.1177\n",
      "Epoch 117/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 1.0683 - val_accuracy: 0.5895 - val_loss: 1.1167\n",
      "Epoch 118/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6090 - loss: 1.0678 - val_accuracy: 0.5875 - val_loss: 1.1146\n",
      "Epoch 119/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6093 - loss: 1.0647 - val_accuracy: 0.5883 - val_loss: 1.1197\n",
      "Epoch 120/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6115 - loss: 1.0672 - val_accuracy: 0.5910 - val_loss: 1.1078\n",
      "Epoch 121/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6102 - loss: 1.0655 - val_accuracy: 0.5898 - val_loss: 1.1135\n",
      "Epoch 122/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6113 - loss: 1.0666 - val_accuracy: 0.5905 - val_loss: 1.1129\n",
      "Epoch 123/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6096 - loss: 1.0659 - val_accuracy: 0.5862 - val_loss: 1.1212\n",
      "Epoch 124/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 108ms/step - accuracy: 0.6113 - loss: 1.0653 - val_accuracy: 0.5919 - val_loss: 1.1077\n",
      "Epoch 125/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 186ms/step - accuracy: 0.6116 - loss: 1.0626 - val_accuracy: 0.5862 - val_loss: 1.1237\n",
      "Epoch 126/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6132 - loss: 1.0574 - val_accuracy: 0.5907 - val_loss: 1.1073\n",
      "Epoch 127/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6118 - loss: 1.0652 - val_accuracy: 0.5916 - val_loss: 1.1098\n",
      "Epoch 128/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6106 - loss: 1.0625 - val_accuracy: 0.5892 - val_loss: 1.1091\n",
      "Epoch 129/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6107 - loss: 1.0641 - val_accuracy: 0.5919 - val_loss: 1.1123\n",
      "Epoch 130/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6121 - loss: 1.0637 - val_accuracy: 0.5912 - val_loss: 1.1035\n",
      "Epoch 131/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.6130 - loss: 1.0613 - val_accuracy: 0.5836 - val_loss: 1.1259\n",
      "Epoch 132/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6144 - loss: 1.0637 - val_accuracy: 0.5942 - val_loss: 1.1046\n",
      "Epoch 133/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6132 - loss: 1.0590 - val_accuracy: 0.5913 - val_loss: 1.1103\n",
      "Epoch 134/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6135 - loss: 1.0587 - val_accuracy: 0.5908 - val_loss: 1.1135\n",
      "Epoch 135/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6117 - loss: 1.0614 - val_accuracy: 0.5891 - val_loss: 1.1128\n",
      "Epoch 136/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6149 - loss: 1.0578 - val_accuracy: 0.5914 - val_loss: 1.1134\n",
      "Epoch 137/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6111 - loss: 1.0592 - val_accuracy: 0.5925 - val_loss: 1.1138\n",
      "Epoch 138/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6125 - loss: 1.0635 - val_accuracy: 0.5903 - val_loss: 1.1186\n",
      "Epoch 139/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6146 - loss: 1.0570 - val_accuracy: 0.5918 - val_loss: 1.1148\n",
      "Epoch 140/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6116 - loss: 1.0590 - val_accuracy: 0.5891 - val_loss: 1.1131\n",
      "Epoch 141/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6123 - loss: 1.0558 - val_accuracy: 0.5881 - val_loss: 1.1166\n",
      "Epoch 142/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6138 - loss: 1.0588 - val_accuracy: 0.5881 - val_loss: 1.1288\n",
      "Epoch 143/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6111 - loss: 1.0603 - val_accuracy: 0.5928 - val_loss: 1.1247\n",
      "Epoch 144/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6141 - loss: 1.0584 - val_accuracy: 0.5907 - val_loss: 1.1018\n",
      "Epoch 145/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6131 - loss: 1.0583 - val_accuracy: 0.5855 - val_loss: 1.1204\n",
      "Epoch 146/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6129 - loss: 1.0614 - val_accuracy: 0.5911 - val_loss: 1.1129\n",
      "Epoch 147/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6163 - loss: 1.0516 - val_accuracy: 0.5905 - val_loss: 1.1076\n",
      "Epoch 148/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1001s\u001b[0m 750ms/step - accuracy: 0.6133 - loss: 1.0574 - val_accuracy: 0.5903 - val_loss: 1.1116\n",
      "Epoch 149/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6137 - loss: 1.0590 - val_accuracy: 0.5875 - val_loss: 1.1176\n",
      "Epoch 150/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6137 - loss: 1.0577 - val_accuracy: 0.5879 - val_loss: 1.1120\n",
      "Epoch 151/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6159 - loss: 1.0544 - val_accuracy: 0.5925 - val_loss: 1.1119\n",
      "Epoch 152/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6163 - loss: 1.0513 - val_accuracy: 0.5916 - val_loss: 1.1085\n",
      "Epoch 153/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1715s\u001b[0m 1s/step - accuracy: 0.6143 - loss: 1.0531 - val_accuracy: 0.5899 - val_loss: 1.1202\n",
      "Epoch 154/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.6177 - loss: 1.0537 - val_accuracy: 0.5934 - val_loss: 1.1119\n",
      "Epoch 155/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 428ms/step - accuracy: 0.6145 - loss: 1.0558 - val_accuracy: 0.5925 - val_loss: 1.1090\n",
      "Epoch 156/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1189s\u001b[0m 890ms/step - accuracy: 0.6144 - loss: 1.0504 - val_accuracy: 0.5906 - val_loss: 1.1132\n",
      "Epoch 157/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 106ms/step - accuracy: 0.6142 - loss: 1.0562 - val_accuracy: 0.5865 - val_loss: 1.1068\n",
      "Epoch 158/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6140 - loss: 1.0563 - val_accuracy: 0.5920 - val_loss: 1.1143\n",
      "Epoch 159/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.6159 - loss: 1.0548 - val_accuracy: 0.5916 - val_loss: 1.1076\n",
      "Epoch 160/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6154 - loss: 1.0505 - val_accuracy: 0.5922 - val_loss: 1.1080\n",
      "Epoch 161/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6160 - loss: 1.0551 - val_accuracy: 0.5892 - val_loss: 1.1112\n",
      "Epoch 162/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.6177 - loss: 1.0516 - val_accuracy: 0.5939 - val_loss: 1.1053\n",
      "Epoch 163/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6164 - loss: 1.0506 - val_accuracy: 0.5884 - val_loss: 1.1104\n",
      "Epoch 164/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6160 - loss: 1.0494 - val_accuracy: 0.5870 - val_loss: 1.1266\n",
      "Epoch 165/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6188 - loss: 1.0437 - val_accuracy: 0.5895 - val_loss: 1.1206\n",
      "Epoch 166/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6177 - loss: 1.0476 - val_accuracy: 0.5954 - val_loss: 1.1146\n",
      "Epoch 167/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6131 - loss: 1.0570 - val_accuracy: 0.5943 - val_loss: 1.1102\n",
      "Epoch 168/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6169 - loss: 1.0502 - val_accuracy: 0.5942 - val_loss: 1.1024\n",
      "Epoch 169/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6162 - loss: 1.0475 - val_accuracy: 0.5944 - val_loss: 1.1087\n",
      "Epoch 170/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6171 - loss: 1.0457 - val_accuracy: 0.5933 - val_loss: 1.1145\n",
      "Epoch 171/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6180 - loss: 1.0485 - val_accuracy: 0.5949 - val_loss: 1.1092\n",
      "Epoch 172/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6172 - loss: 1.0508 - val_accuracy: 0.5946 - val_loss: 1.1062\n",
      "Epoch 173/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6200 - loss: 1.0442 - val_accuracy: 0.5925 - val_loss: 1.1093\n",
      "Epoch 174/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6156 - loss: 1.0556 - val_accuracy: 0.5944 - val_loss: 1.1125\n",
      "Epoch 175/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6181 - loss: 1.0473 - val_accuracy: 0.5939 - val_loss: 1.1009\n",
      "Epoch 176/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6165 - loss: 1.0492 - val_accuracy: 0.5928 - val_loss: 1.1119\n",
      "Epoch 177/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6165 - loss: 1.0473 - val_accuracy: 0.5939 - val_loss: 1.1137\n",
      "Epoch 178/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6171 - loss: 1.0467 - val_accuracy: 0.5920 - val_loss: 1.1040\n",
      "Epoch 179/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6161 - loss: 1.0496 - val_accuracy: 0.5940 - val_loss: 1.1081\n",
      "Epoch 180/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6191 - loss: 1.0471 - val_accuracy: 0.5885 - val_loss: 1.1181\n",
      "Epoch 181/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6152 - loss: 1.0479 - val_accuracy: 0.5905 - val_loss: 1.1182\n",
      "Epoch 182/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6164 - loss: 1.0515 - val_accuracy: 0.5887 - val_loss: 1.1192\n",
      "Epoch 183/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.6166 - loss: 1.0478 - val_accuracy: 0.5933 - val_loss: 1.1063\n",
      "Epoch 184/200\n",
      "\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.6194 - loss: 1.0455 - val_accuracy: 0.5962 - val_loss: 1.0992\n",
      "Epoch 185/200\n",
      "\u001b[1m 410/1336\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.6150 - loss: 1.0456"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m cnn\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m125\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m pred_probs \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     10\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(pred_probs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mIterator, tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[39m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m opt_outputs\u001b[39m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.fit(X_train,y_train,epochs=200,validation_split=0.2,batch_size=125)\n",
    "\n",
    "pred_probs = cnn.predict(X_test)\n",
    "pred = np.argmax(pred_probs, axis=1)\n",
    "print(np.mean(pred==y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/2_and_3_combined.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3c82d000bb8a1750346fb87c49af9771012dc5d265e5e793ee442432926adf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
