{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/large_board_dataset2.csv\")\n",
    "#df2 = pd.read_csv(\"data/large_board_dataset2-mikala.csv\")\n",
    "#df = pd.concat([df1, df2], axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>whose_turn</th>\n",
       "      <th>opponent_level</th>\n",
       "      <th>player_level</th>\n",
       "      <th>game</th>\n",
       "      <th>random_moves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>4</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64587</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64588</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64589</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64590</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64591</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64592 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       x  y whose_turn   \n",
       "0      (np.float64(0.0), np.float64(0.0), np.float64(...  3        red  \\\n",
       "1      (np.float64(0.0), np.float64(0.0), np.float64(...  4     yellow   \n",
       "2      (np.float64(0.0), np.float64(0.0), np.float64(...  3        red   \n",
       "3      (np.float64(0.0), np.float64(0.0), np.float64(...  3     yellow   \n",
       "4      (np.float64(0.0), np.float64(0.0), np.float64(...  3        red   \n",
       "...                                                  ... ..        ...   \n",
       "64587  (np.float64(0.0), np.float64(0.0), np.float64(...  3     yellow   \n",
       "64588  (np.float64(0.0), np.float64(0.0), np.float64(...  0        red   \n",
       "64589  (np.float64(0.0), np.float64(0.0), np.float64(...  3     yellow   \n",
       "64590  (np.float64(0.0), np.float64(0.0), np.float64(...  2        red   \n",
       "64591  (np.float64(0.0), np.float64(0.0), np.float64(...  3     yellow   \n",
       "\n",
       "       opponent_level  player_level  game  random_moves  \n",
       "0                1500          1500     0             3  \n",
       "1                1500          1500     0             3  \n",
       "2                1500          1500     0             3  \n",
       "3                1500          1500     0             3  \n",
       "4                1500          1500     0             3  \n",
       "...               ...           ...   ...           ...  \n",
       "64587            1500          1500  2999            10  \n",
       "64588            1500          1500  2999            10  \n",
       "64589            1500          1500  2999            10  \n",
       "64590            1500          1500  2999            10  \n",
       "64591            1500          1500  2999            10  \n",
       "\n",
       "[64592 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>whose_turn</th>\n",
       "      <th>opponent_level</th>\n",
       "      <th>player_level</th>\n",
       "      <th>game</th>\n",
       "      <th>random_moves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64587</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64588</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>0</td>\n",
       "      <td>red</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64589</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64590</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64591</th>\n",
       "      <td>(np.float64(0.0), np.float64(0.0), np.float64(...</td>\n",
       "      <td>3</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>2999</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       x  y whose_turn   \n",
       "64587  (np.float64(0.0), np.float64(0.0), np.float64(...  3     yellow  \\\n",
       "64588  (np.float64(0.0), np.float64(0.0), np.float64(...  0        red   \n",
       "64589  (np.float64(0.0), np.float64(0.0), np.float64(...  3     yellow   \n",
       "64590  (np.float64(0.0), np.float64(0.0), np.float64(...  2        red   \n",
       "64591  (np.float64(0.0), np.float64(0.0), np.float64(...  3     yellow   \n",
       "\n",
       "       opponent_level  player_level  game  random_moves  \n",
       "64587            1500          1500  2999            10  \n",
       "64588            1500          1500  2999            10  \n",
       "64589            1500          1500  2999            10  \n",
       "64590            1500          1500  2999            10  \n",
       "64591            1500          1500  2999            10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df[\"x\"] = df[\"x\"].apply(lambda x: np.array(ast.literal_eval(x)).reshape(2, 6, 7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"x\"]\n",
    "y = df[\"y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 22)\n",
    "\n",
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)\n",
    "y_train = np.array(y_train)  \n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train = X_train.transpose(0, 2, 3, 1)  # Convert (num_samples, 2, 6, 7) to (num_samples, 6, 7, 2)\n",
    "X_test = X_test.transpose(0, 2, 3, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_board(board):\n",
    "    if board[\"whose_turn\"] != \"red\":\n",
    "        # Flip the layers to make each board look like it's from the perspective of \"red\", aka plus\n",
    "        board[\"x\"] = board[\"x\"][::-1, :, :]\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(preprocess_board, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=64,kernel_size=(4,4),activation=tf.nn.relu,input_shape=(6, 7, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu),\n",
    "        # had to adjust data_format because it was treating the images as 2x6 with 7 channels\n",
    "        tf.keras.layers.MaxPooling2D(pool_size = (2,2),strides=(1, 1), padding = \"same\"),\n",
    "        tf.keras.layers.Conv2D(64, (1, 1), activation=tf.nn.relu),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128,activation=tf.nn.relu,kernel_regularizer = tf.keras.regularizers.l2(0.0002)),\n",
    "        tf.keras.layers.Dense(64,activation=tf.nn.relu,kernel_regularizer = tf.keras.regularizers.l2(0.0005)),\n",
    "        tf.keras.layers.Dense(7,activation=tf.nn.softmax)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_14 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,447</span> (427.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,447\u001b[0m (427.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,447</span> (427.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,447\u001b[0m (427.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.2369 - loss: 1.8818 - val_accuracy: 0.3861 - val_loss: 1.5725\n",
      "Epoch 2/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4162 - loss: 1.4974 - val_accuracy: 0.4485 - val_loss: 1.4256\n",
      "Epoch 3/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4753 - loss: 1.3618 - val_accuracy: 0.4671 - val_loss: 1.3798\n",
      "Epoch 4/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4927 - loss: 1.3102 - val_accuracy: 0.4710 - val_loss: 1.3688\n",
      "Epoch 5/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5163 - loss: 1.2599 - val_accuracy: 0.4755 - val_loss: 1.3479\n",
      "Epoch 6/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5347 - loss: 1.2185 - val_accuracy: 0.4827 - val_loss: 1.3487\n",
      "Epoch 7/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5520 - loss: 1.1727 - val_accuracy: 0.4820 - val_loss: 1.3464\n",
      "Epoch 8/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5700 - loss: 1.1362 - val_accuracy: 0.4854 - val_loss: 1.3530\n",
      "Epoch 9/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5884 - loss: 1.0888 - val_accuracy: 0.4906 - val_loss: 1.3524\n",
      "Epoch 10/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6034 - loss: 1.0591 - val_accuracy: 0.4902 - val_loss: 1.3679\n",
      "Epoch 11/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6166 - loss: 1.0238 - val_accuracy: 0.4937 - val_loss: 1.3849\n",
      "Epoch 12/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6351 - loss: 0.9766 - val_accuracy: 0.4899 - val_loss: 1.3864\n",
      "Epoch 13/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6534 - loss: 0.9358 - val_accuracy: 0.4867 - val_loss: 1.4296\n",
      "Epoch 14/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6656 - loss: 0.9073 - val_accuracy: 0.4882 - val_loss: 1.4464\n",
      "Epoch 15/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6807 - loss: 0.8747 - val_accuracy: 0.4864 - val_loss: 1.4520\n",
      "Epoch 16/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6855 - loss: 0.8518 - val_accuracy: 0.4850 - val_loss: 1.4808\n",
      "Epoch 17/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6985 - loss: 0.8308 - val_accuracy: 0.4836 - val_loss: 1.5364\n",
      "Epoch 18/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7104 - loss: 0.8021 - val_accuracy: 0.4839 - val_loss: 1.5317\n",
      "Epoch 19/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7171 - loss: 0.7673 - val_accuracy: 0.4774 - val_loss: 1.5830\n",
      "Epoch 20/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7288 - loss: 0.7431 - val_accuracy: 0.4797 - val_loss: 1.6116\n",
      "Epoch 21/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7413 - loss: 0.7163 - val_accuracy: 0.4786 - val_loss: 1.7050\n",
      "Epoch 22/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7564 - loss: 0.6856 - val_accuracy: 0.4787 - val_loss: 1.6912\n",
      "Epoch 23/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7582 - loss: 0.6668 - val_accuracy: 0.4824 - val_loss: 1.7245\n",
      "Epoch 24/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7707 - loss: 0.6411 - val_accuracy: 0.4728 - val_loss: 1.8022\n",
      "Epoch 25/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7805 - loss: 0.6172 - val_accuracy: 0.4802 - val_loss: 1.7842\n",
      "Epoch 26/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7833 - loss: 0.6070 - val_accuracy: 0.4816 - val_loss: 1.8585\n",
      "Epoch 27/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7923 - loss: 0.5824 - val_accuracy: 0.4813 - val_loss: 1.8942\n",
      "Epoch 28/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8050 - loss: 0.5586 - val_accuracy: 0.4772 - val_loss: 1.9377\n",
      "Epoch 29/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8099 - loss: 0.5467 - val_accuracy: 0.4768 - val_loss: 1.9708\n",
      "Epoch 30/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8128 - loss: 0.5357 - val_accuracy: 0.4747 - val_loss: 2.0379\n",
      "Epoch 31/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8215 - loss: 0.5128 - val_accuracy: 0.4778 - val_loss: 2.0942\n",
      "Epoch 32/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8288 - loss: 0.4962 - val_accuracy: 0.4774 - val_loss: 2.1711\n",
      "Epoch 33/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8324 - loss: 0.4816 - val_accuracy: 0.4744 - val_loss: 2.1861\n",
      "Epoch 34/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8381 - loss: 0.4688 - val_accuracy: 0.4705 - val_loss: 2.2077\n",
      "Epoch 35/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8404 - loss: 0.4583 - val_accuracy: 0.4694 - val_loss: 2.3086\n",
      "Epoch 36/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8461 - loss: 0.4459 - val_accuracy: 0.4723 - val_loss: 2.3053\n",
      "Epoch 37/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8496 - loss: 0.4344 - val_accuracy: 0.4733 - val_loss: 2.3313\n",
      "Epoch 38/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8576 - loss: 0.4163 - val_accuracy: 0.4664 - val_loss: 2.4349\n",
      "Epoch 39/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8594 - loss: 0.4080 - val_accuracy: 0.4683 - val_loss: 2.5157\n",
      "Epoch 40/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8601 - loss: 0.4077 - val_accuracy: 0.4706 - val_loss: 2.5367\n",
      "Epoch 41/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8631 - loss: 0.3996 - val_accuracy: 0.4706 - val_loss: 2.5206\n",
      "Epoch 42/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8732 - loss: 0.3817 - val_accuracy: 0.4775 - val_loss: 2.5720\n",
      "Epoch 43/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8755 - loss: 0.3685 - val_accuracy: 0.4685 - val_loss: 2.6881\n",
      "Epoch 44/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8754 - loss: 0.3672 - val_accuracy: 0.4672 - val_loss: 2.6490\n",
      "Epoch 45/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8769 - loss: 0.3618 - val_accuracy: 0.4766 - val_loss: 2.7313\n",
      "Epoch 46/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8836 - loss: 0.3495 - val_accuracy: 0.4703 - val_loss: 2.7266\n",
      "Epoch 47/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8846 - loss: 0.3388 - val_accuracy: 0.4731 - val_loss: 2.8475\n",
      "Epoch 48/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8865 - loss: 0.3408 - val_accuracy: 0.4680 - val_loss: 2.8299\n",
      "Epoch 49/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8926 - loss: 0.3262 - val_accuracy: 0.4684 - val_loss: 2.8417\n",
      "Epoch 50/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8928 - loss: 0.3246 - val_accuracy: 0.4673 - val_loss: 2.9423\n",
      "Epoch 51/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8942 - loss: 0.3232 - val_accuracy: 0.4775 - val_loss: 2.9522\n",
      "Epoch 52/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8935 - loss: 0.3171 - val_accuracy: 0.4756 - val_loss: 2.9620\n",
      "Epoch 53/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9006 - loss: 0.3012 - val_accuracy: 0.4688 - val_loss: 3.0273\n",
      "Epoch 54/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8970 - loss: 0.3097 - val_accuracy: 0.4706 - val_loss: 3.0844\n",
      "Epoch 55/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9023 - loss: 0.2960 - val_accuracy: 0.4726 - val_loss: 3.1022\n",
      "Epoch 56/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9039 - loss: 0.2915 - val_accuracy: 0.4697 - val_loss: 3.1532\n",
      "Epoch 57/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8969 - loss: 0.3034 - val_accuracy: 0.4743 - val_loss: 3.1517\n",
      "Epoch 58/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9097 - loss: 0.2793 - val_accuracy: 0.4686 - val_loss: 3.1494\n",
      "Epoch 59/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9083 - loss: 0.2752 - val_accuracy: 0.4745 - val_loss: 3.2133\n",
      "Epoch 60/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9130 - loss: 0.2691 - val_accuracy: 0.4693 - val_loss: 3.1461\n",
      "Epoch 61/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9116 - loss: 0.2684 - val_accuracy: 0.4706 - val_loss: 3.3058\n",
      "Epoch 62/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9151 - loss: 0.2696 - val_accuracy: 0.4705 - val_loss: 3.3118\n",
      "Epoch 63/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9112 - loss: 0.2698 - val_accuracy: 0.4708 - val_loss: 3.3530\n",
      "Epoch 64/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9149 - loss: 0.2627 - val_accuracy: 0.4718 - val_loss: 3.3518\n",
      "Epoch 65/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9180 - loss: 0.2533 - val_accuracy: 0.4721 - val_loss: 3.5059\n",
      "Epoch 66/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9184 - loss: 0.2541 - val_accuracy: 0.4686 - val_loss: 3.6885\n",
      "Epoch 67/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9150 - loss: 0.2589 - val_accuracy: 0.4703 - val_loss: 3.5444\n",
      "Epoch 68/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9186 - loss: 0.2523 - val_accuracy: 0.4688 - val_loss: 3.5456\n",
      "Epoch 69/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9197 - loss: 0.2448 - val_accuracy: 0.4680 - val_loss: 3.6194\n",
      "Epoch 70/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9240 - loss: 0.2395 - val_accuracy: 0.4715 - val_loss: 3.6575\n",
      "Epoch 71/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2406 - val_accuracy: 0.4682 - val_loss: 3.6079\n",
      "Epoch 72/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9218 - loss: 0.2411 - val_accuracy: 0.4675 - val_loss: 3.5835\n",
      "Epoch 73/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9236 - loss: 0.2371 - val_accuracy: 0.4696 - val_loss: 3.6332\n",
      "Epoch 74/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9240 - loss: 0.2336 - val_accuracy: 0.4647 - val_loss: 3.7002\n",
      "Epoch 75/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9243 - loss: 0.2322 - val_accuracy: 0.4699 - val_loss: 3.7917\n",
      "Epoch 76/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9262 - loss: 0.2299 - val_accuracy: 0.4714 - val_loss: 3.7468\n",
      "Epoch 77/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9260 - loss: 0.2329 - val_accuracy: 0.4724 - val_loss: 3.7904\n",
      "Epoch 78/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9297 - loss: 0.2204 - val_accuracy: 0.4700 - val_loss: 3.8528\n",
      "Epoch 79/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.2285 - val_accuracy: 0.4688 - val_loss: 3.8249\n",
      "Epoch 80/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9286 - loss: 0.2239 - val_accuracy: 0.4702 - val_loss: 3.8851\n",
      "Epoch 81/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.2160 - val_accuracy: 0.4666 - val_loss: 3.7923\n",
      "Epoch 82/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9310 - loss: 0.2135 - val_accuracy: 0.4648 - val_loss: 3.9682\n",
      "Epoch 83/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.2042 - val_accuracy: 0.4654 - val_loss: 3.7570\n",
      "Epoch 84/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9284 - loss: 0.2222 - val_accuracy: 0.4673 - val_loss: 3.9292\n",
      "Epoch 85/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.2229 - val_accuracy: 0.4740 - val_loss: 3.8485\n",
      "Epoch 86/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9308 - loss: 0.2145 - val_accuracy: 0.4718 - val_loss: 3.9446\n",
      "Epoch 87/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9357 - loss: 0.2054 - val_accuracy: 0.4696 - val_loss: 3.9369\n",
      "Epoch 88/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9365 - loss: 0.2010 - val_accuracy: 0.4725 - val_loss: 3.9540\n",
      "Epoch 89/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9314 - loss: 0.2110 - val_accuracy: 0.4707 - val_loss: 4.0136\n",
      "Epoch 90/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9348 - loss: 0.2001 - val_accuracy: 0.4639 - val_loss: 4.1424\n",
      "Epoch 91/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9329 - loss: 0.2113 - val_accuracy: 0.4645 - val_loss: 4.1763\n",
      "Epoch 92/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9368 - loss: 0.1969 - val_accuracy: 0.4703 - val_loss: 3.9564\n",
      "Epoch 93/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9383 - loss: 0.1959 - val_accuracy: 0.4690 - val_loss: 4.0740\n",
      "Epoch 94/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9401 - loss: 0.1921 - val_accuracy: 0.4695 - val_loss: 4.1620\n",
      "Epoch 95/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9389 - loss: 0.1920 - val_accuracy: 0.4711 - val_loss: 4.1258\n",
      "Epoch 96/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9364 - loss: 0.1982 - val_accuracy: 0.4677 - val_loss: 4.2167\n",
      "Epoch 97/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9386 - loss: 0.1930 - val_accuracy: 0.4625 - val_loss: 4.1473\n",
      "Epoch 98/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9382 - loss: 0.1921 - val_accuracy: 0.4682 - val_loss: 4.2855\n",
      "Epoch 99/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.1891 - val_accuracy: 0.4676 - val_loss: 4.1580\n",
      "Epoch 100/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9395 - loss: 0.1900 - val_accuracy: 0.4717 - val_loss: 4.2512\n",
      "Epoch 101/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9424 - loss: 0.1834 - val_accuracy: 0.4634 - val_loss: 4.0928\n",
      "Epoch 102/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9435 - loss: 0.1783 - val_accuracy: 0.4680 - val_loss: 4.3003\n",
      "Epoch 103/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.1889 - val_accuracy: 0.4642 - val_loss: 4.2114\n",
      "Epoch 104/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.1854 - val_accuracy: 0.4653 - val_loss: 4.2041\n",
      "Epoch 105/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9425 - loss: 0.1841 - val_accuracy: 0.4680 - val_loss: 4.3064\n",
      "Epoch 106/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.1809 - val_accuracy: 0.4650 - val_loss: 4.4354\n",
      "Epoch 107/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9429 - loss: 0.1808 - val_accuracy: 0.4695 - val_loss: 4.2505\n",
      "Epoch 108/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1746 - val_accuracy: 0.4680 - val_loss: 4.3679\n",
      "Epoch 109/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9457 - loss: 0.1724 - val_accuracy: 0.4659 - val_loss: 4.2399\n",
      "Epoch 110/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.1849 - val_accuracy: 0.4687 - val_loss: 4.3138\n",
      "Epoch 111/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9425 - loss: 0.1758 - val_accuracy: 0.4682 - val_loss: 4.3658\n",
      "Epoch 112/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9431 - loss: 0.1800 - val_accuracy: 0.4691 - val_loss: 4.3883\n",
      "Epoch 113/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9458 - loss: 0.1709 - val_accuracy: 0.4655 - val_loss: 4.2603\n",
      "Epoch 114/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9453 - loss: 0.1712 - val_accuracy: 0.4642 - val_loss: 4.2860\n",
      "Epoch 115/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9404 - loss: 0.1815 - val_accuracy: 0.4655 - val_loss: 4.4425\n",
      "Epoch 116/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9476 - loss: 0.1630 - val_accuracy: 0.4731 - val_loss: 4.3334\n",
      "Epoch 117/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.1754 - val_accuracy: 0.4685 - val_loss: 4.2538\n",
      "Epoch 118/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9458 - loss: 0.1673 - val_accuracy: 0.4700 - val_loss: 4.5587\n",
      "Epoch 119/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1637 - val_accuracy: 0.4613 - val_loss: 4.4222\n",
      "Epoch 120/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9426 - loss: 0.1738 - val_accuracy: 0.4620 - val_loss: 4.4567\n",
      "Epoch 121/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.1735 - val_accuracy: 0.4673 - val_loss: 4.3980\n",
      "Epoch 122/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.1494 - val_accuracy: 0.4683 - val_loss: 4.4928\n",
      "Epoch 123/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9531 - loss: 0.1535 - val_accuracy: 0.4685 - val_loss: 4.3155\n",
      "Epoch 124/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.1711 - val_accuracy: 0.4681 - val_loss: 4.4839\n",
      "Epoch 125/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.1578 - val_accuracy: 0.4731 - val_loss: 4.5908\n",
      "Epoch 126/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9503 - loss: 0.1554 - val_accuracy: 0.4698 - val_loss: 4.5043\n",
      "Epoch 127/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1663 - val_accuracy: 0.4686 - val_loss: 4.4668\n",
      "Epoch 128/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1588 - val_accuracy: 0.4668 - val_loss: 4.6059\n",
      "Epoch 129/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9490 - loss: 0.1598 - val_accuracy: 0.4697 - val_loss: 4.3858\n",
      "Epoch 130/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9444 - loss: 0.1683 - val_accuracy: 0.4665 - val_loss: 4.5293\n",
      "Epoch 131/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9472 - loss: 0.1633 - val_accuracy: 0.4652 - val_loss: 4.4422\n",
      "Epoch 132/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9494 - loss: 0.1580 - val_accuracy: 0.4667 - val_loss: 4.4922\n",
      "Epoch 133/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9501 - loss: 0.1568 - val_accuracy: 0.4682 - val_loss: 4.6363\n",
      "Epoch 134/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9485 - loss: 0.1591 - val_accuracy: 0.4659 - val_loss: 4.7232\n",
      "Epoch 135/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9529 - loss: 0.1509 - val_accuracy: 0.4613 - val_loss: 4.6125\n",
      "Epoch 136/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9532 - loss: 0.1472 - val_accuracy: 0.4663 - val_loss: 4.5219\n",
      "Epoch 137/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9484 - loss: 0.1549 - val_accuracy: 0.4705 - val_loss: 4.5044\n",
      "Epoch 138/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9523 - loss: 0.1509 - val_accuracy: 0.4714 - val_loss: 4.7303\n",
      "Epoch 139/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9525 - loss: 0.1502 - val_accuracy: 0.4737 - val_loss: 4.8113\n",
      "Epoch 140/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9486 - loss: 0.1606 - val_accuracy: 0.4646 - val_loss: 4.6073\n",
      "Epoch 141/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9469 - loss: 0.1643 - val_accuracy: 0.4695 - val_loss: 4.5949\n",
      "Epoch 142/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1519 - val_accuracy: 0.4650 - val_loss: 4.6582\n",
      "Epoch 143/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9539 - loss: 0.1465 - val_accuracy: 0.4647 - val_loss: 4.6508\n",
      "Epoch 144/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1415 - val_accuracy: 0.4703 - val_loss: 4.6936\n",
      "Epoch 145/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1572 - val_accuracy: 0.4679 - val_loss: 4.6640\n",
      "Epoch 146/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9563 - loss: 0.1405 - val_accuracy: 0.4676 - val_loss: 4.7284\n",
      "Epoch 147/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9488 - loss: 0.1558 - val_accuracy: 0.4707 - val_loss: 4.7590\n",
      "Epoch 148/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9524 - loss: 0.1496 - val_accuracy: 0.4700 - val_loss: 4.8282\n",
      "Epoch 149/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.1615 - val_accuracy: 0.4683 - val_loss: 4.8430\n",
      "Epoch 150/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9493 - loss: 0.1553 - val_accuracy: 0.4695 - val_loss: 4.6730\n",
      "Epoch 151/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9526 - loss: 0.1475 - val_accuracy: 0.4671 - val_loss: 4.7049\n",
      "Epoch 152/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.1377 - val_accuracy: 0.4654 - val_loss: 4.7041\n",
      "Epoch 153/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9526 - loss: 0.1496 - val_accuracy: 0.4653 - val_loss: 4.4485\n",
      "Epoch 154/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9503 - loss: 0.1523 - val_accuracy: 0.4683 - val_loss: 4.6994\n",
      "Epoch 155/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1361 - val_accuracy: 0.4658 - val_loss: 4.9246\n",
      "Epoch 156/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9523 - loss: 0.1491 - val_accuracy: 0.4724 - val_loss: 4.8467\n",
      "Epoch 157/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1414 - val_accuracy: 0.4631 - val_loss: 4.7690\n",
      "Epoch 158/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.1456 - val_accuracy: 0.4666 - val_loss: 4.8015\n",
      "Epoch 159/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9573 - loss: 0.1354 - val_accuracy: 0.4612 - val_loss: 4.6654\n",
      "Epoch 160/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9494 - loss: 0.1552 - val_accuracy: 0.4660 - val_loss: 4.7739\n",
      "Epoch 161/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9534 - loss: 0.1489 - val_accuracy: 0.4642 - val_loss: 4.7822\n",
      "Epoch 162/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.1393 - val_accuracy: 0.4654 - val_loss: 4.9494\n",
      "Epoch 163/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9525 - loss: 0.1444 - val_accuracy: 0.4631 - val_loss: 4.8411\n",
      "Epoch 164/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9533 - loss: 0.1434 - val_accuracy: 0.4665 - val_loss: 4.8494\n",
      "Epoch 165/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9552 - loss: 0.1381 - val_accuracy: 0.4658 - val_loss: 4.8114\n",
      "Epoch 166/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9545 - loss: 0.1385 - val_accuracy: 0.4672 - val_loss: 4.7104\n",
      "Epoch 167/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9516 - loss: 0.1453 - val_accuracy: 0.4666 - val_loss: 4.8019\n",
      "Epoch 168/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.1311 - val_accuracy: 0.4601 - val_loss: 5.1834\n",
      "Epoch 169/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9528 - loss: 0.1432 - val_accuracy: 0.4664 - val_loss: 4.8473\n",
      "Epoch 170/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1300 - val_accuracy: 0.4659 - val_loss: 4.9993\n",
      "Epoch 171/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.1408 - val_accuracy: 0.4632 - val_loss: 4.7785\n",
      "Epoch 172/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9572 - loss: 0.1333 - val_accuracy: 0.4669 - val_loss: 4.8657\n",
      "Epoch 173/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9595 - loss: 0.1292 - val_accuracy: 0.4645 - val_loss: 5.0805\n",
      "Epoch 174/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.1410 - val_accuracy: 0.4679 - val_loss: 5.0029\n",
      "Epoch 175/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9588 - loss: 0.1298 - val_accuracy: 0.4675 - val_loss: 5.0892\n",
      "Epoch 176/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.1431 - val_accuracy: 0.4678 - val_loss: 4.9266\n",
      "Epoch 177/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9555 - loss: 0.1377 - val_accuracy: 0.4656 - val_loss: 4.8624\n",
      "Epoch 178/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.1358 - val_accuracy: 0.4687 - val_loss: 4.9641\n",
      "Epoch 179/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 77ms/step - accuracy: 0.9550 - loss: 0.1359 - val_accuracy: 0.4670 - val_loss: 4.9741\n",
      "Epoch 180/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9597 - loss: 0.1291 - val_accuracy: 0.4668 - val_loss: 5.0655\n",
      "Epoch 181/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1805s\u001b[0m 4s/step - accuracy: 0.9591 - loss: 0.1283 - val_accuracy: 0.4667 - val_loss: 4.8796\n",
      "Epoch 182/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9587 - loss: 0.1279 - val_accuracy: 0.4623 - val_loss: 5.0658\n",
      "Epoch 183/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9564 - loss: 0.1332 - val_accuracy: 0.4613 - val_loss: 4.9332\n",
      "Epoch 184/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9503 - loss: 0.1462 - val_accuracy: 0.4669 - val_loss: 5.0168\n",
      "Epoch 185/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9584 - loss: 0.1332 - val_accuracy: 0.4666 - val_loss: 5.0990\n",
      "Epoch 186/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9579 - loss: 0.1302 - val_accuracy: 0.4650 - val_loss: 5.2752\n",
      "Epoch 187/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9556 - loss: 0.1365 - val_accuracy: 0.4699 - val_loss: 5.0932\n",
      "Epoch 188/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9600 - loss: 0.1265 - val_accuracy: 0.4633 - val_loss: 5.3952\n",
      "Epoch 189/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9563 - loss: 0.1329 - val_accuracy: 0.4665 - val_loss: 5.0165\n",
      "Epoch 190/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9561 - loss: 0.1404 - val_accuracy: 0.4633 - val_loss: 5.0720\n",
      "Epoch 191/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9606 - loss: 0.1238 - val_accuracy: 0.4648 - val_loss: 5.0978\n",
      "Epoch 192/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9597 - loss: 0.1247 - val_accuracy: 0.4676 - val_loss: 5.1042\n",
      "Epoch 193/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9570 - loss: 0.1305 - val_accuracy: 0.4661 - val_loss: 4.9047\n",
      "Epoch 194/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9542 - loss: 0.1379 - val_accuracy: 0.4651 - val_loss: 5.0444\n",
      "Epoch 195/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9567 - loss: 0.1323 - val_accuracy: 0.4592 - val_loss: 5.1325\n",
      "Epoch 196/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.1309 - val_accuracy: 0.4678 - val_loss: 4.9843\n",
      "Epoch 197/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9603 - loss: 0.1226 - val_accuracy: 0.4689 - val_loss: 5.2164\n",
      "Epoch 198/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9584 - loss: 0.1279 - val_accuracy: 0.4687 - val_loss: 5.1405\n",
      "Epoch 199/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9606 - loss: 0.1209 - val_accuracy: 0.4674 - val_loss: 4.9642\n",
      "Epoch 200/200\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9604 - loss: 0.1221 - val_accuracy: 0.4640 - val_loss: 5.0915\n",
      "\u001b[1m409/409\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "0.4647013782542113\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "cnn.fit(X_train,y_train,epochs=200,validation_split=0.2,batch_size=100)\n",
    "\n",
    "pred_probs = cnn.predict(X_test)\n",
    "pred = np.argmax(pred_probs, axis=1)\n",
    "print(np.mean(pred==y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtype: object, shape: (52238,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train dtype: {X_train.dtype}, shape: {X_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65298"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3c82d000bb8a1750346fb87c49af9771012dc5d265e5e793ee442432926adf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
